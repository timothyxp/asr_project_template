{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "\n",
    "\n",
    "def calc_cer(target_text, predicted_text) -> float:\n",
    "    if len(target_text) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return editdistance.distance(predicted_text, target_text) / len(target_text)\n",
    "\n",
    "\n",
    "def calc_wer(target_text, predicted_text) -> float:\n",
    "    target_text, predicted_text = target_text.split(' '), predicted_text.split(' ')\n",
    "    if len(target_text) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return editdistance.distance(predicted_text, target_text) / len(target_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for target, pred, expected_wer, expected_cer in [\n",
    "    (\"if you can not measure it you can not improve it\", \n",
    "     \"if you can nt measure t yo can not i\", \n",
    "     0.454, 0.25),\n",
    "    (\"if you cant describe what you are doing as a process you dont know what youre doing\", \n",
    "     \"if you cant describe what you are doing as a process you dont know what youre doing\", \n",
    "     0.0, 0.0),\n",
    "    (\"one measurement is worth a thousand expert opinions\", \n",
    "     \"one  is worth thousand opinions\", \n",
    "     0.375, 0.392)\n",
    "]:\n",
    "    wer = calc_wer(target, pred)\n",
    "    cer = calc_cer(target, pred)\n",
    "    assert np.isclose(wer, expected_wer, atol=1e-3), f\"true: {target}, pred: {pred}, expected wer {expected_wer} != your wer {wer}\"\n",
    "    assert np.isclose(cer, expected_cer, atol=1e-3), f\"true: {target}, pred: {pred}, expected cer {expected_cer} != your cer {cer}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw_asr.text_encoder.ctc_char_text_encoder import CTCCharTextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CTCCharTextEncoder.get_simple_alphabet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = torch.load(\"log_probs.pth\")\n",
    "input_lengths = torch.load(\"input_lengths.pth\")\n",
    "targets = torch.load(\"targets.pth\")\n",
    "target_lengths = torch.load(\"target_lengths.pth\")\n",
    "spectrogram1 = torch.load('spectrogram1.pth')\n",
    "spectrogram2 = torch.load('spectrogram2.pth')\n",
    "\n",
    "result = torch.load('result.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CTCLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([658, 4, 28]),\n",
       " torch.Size([4, 127]),\n",
       " torch.Size([4]),\n",
       " torch.Size([4]),\n",
       " torch.Size([4, 658, 128]),\n",
       " torch.Size([4, 658, 128]),\n",
       " torch.Size([4, 658, 128]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.shape, targets.shape, input_lengths.shape, target_lengths.shape, spectrogram1.shape, spectrogram2.shape, result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CTCLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1587.6580, 1313.0886, 1682.4307, 1681.2706], grad_fn=<CtcLossBackward>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(log_probs=log_probs, targets=targets,\n",
    "                               input_lengths=input_lengths, target_lengths=target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([112,  82, 127, 124])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([615, 500, 656, 658])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 6.2123e+02, 3.3449e+03, 0.0000e+00, 2.2509e+02, 2.6115e+02,\n",
       "         0.0000e+00, 1.3664e+01, 1.4962e+00, 9.6077e+01, 1.1065e+02, 4.1968e+01,\n",
       "         2.6610e+02, 0.0000e+00, 4.1583e+00, 4.1194e-01, 2.9761e+01, 8.5165e+00,\n",
       "         2.3186e+00, 8.5824e-01],\n",
       "        [0.0000e+00, 6.8417e-01, 3.6837e+00, 0.0000e+00, 1.1331e+02, 1.3147e+02,\n",
       "         0.0000e+00, 3.6135e+02, 3.9570e+01, 1.4662e+02, 1.6886e+02, 3.3999e+01,\n",
       "         2.1557e+02, 0.0000e+00, 1.6303e+02, 1.6151e+01, 1.1135e+01, 3.1863e+00,\n",
       "         1.0416e+01, 3.8554e+00],\n",
       "        [0.0000e+00, 2.3120e-02, 1.2448e-01, 0.0000e+00, 1.4084e+00, 1.6341e+00,\n",
       "         0.0000e+00, 6.4227e+00, 7.0331e-01, 1.4390e+00, 1.6572e+00, 9.6978e-02,\n",
       "         6.1489e-01, 0.0000e+00, 2.4434e-02, 2.4206e-03, 2.3275e-01, 6.6603e-02,\n",
       "         3.4645e-01, 1.2824e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram1[:, 0, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.0737, -0.0737,  0.0000, -0.4424, -0.4424,  0.0000, -0.4050,\n",
       "         -0.4050, -0.4306, -0.4306, -0.4426, -0.4426,  0.0000, -0.4436, -0.4436,\n",
       "         -0.3608, -0.3608, -0.3634, -0.3634],\n",
       "        [ 0.0000, -0.0749, -0.0749,  0.0000, -0.4426, -0.4426,  0.0000, -0.4048,\n",
       "         -0.4048, -0.4305, -0.4305, -0.4427, -0.4427,  0.0000, -0.4435, -0.4435,\n",
       "         -0.3608, -0.3608, -0.3634, -0.3634],\n",
       "        [ 0.0000, -0.0749, -0.0749,  0.0000, -0.4429, -0.4429,  0.0000, -0.4050,\n",
       "         -0.4050, -0.4307, -0.4307, -0.4428, -0.4428,  0.0000, -0.4436, -0.4436,\n",
       "         -0.3608, -0.3608, -0.3634, -0.3634],\n",
       "        [ 0.0000, -0.0749, -0.0749,  0.0000, -0.4429, -0.4429,  0.0000, -0.4050,\n",
       "         -0.4050, -0.4307, -0.4307, -0.4428, -0.4428,  0.0000, -0.4436, -0.4436,\n",
       "         -0.3608, -0.3608, -0.3634, -0.3634]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram2[:, 0, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0191,  0.0049,  0.0198, -0.0161, -0.0310],\n",
       "        [ 0.0191,  0.0049,  0.0198, -0.0161, -0.0310],\n",
       "        [ 0.0191,  0.0049,  0.0198, -0.0161, -0.0310],\n",
       "        [ 0.0191,  0.0049,  0.0198, -0.0161, -0.0310]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:, 0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.2745, -3.3577, -3.3136, -3.2968, -3.3361],\n",
       "        [-3.2745, -3.3577, -3.3136, -3.2968, -3.3361],\n",
       "        [-3.2745, -3.3577, -3.3136, -3.2968, -3.3361],\n",
       "        [-3.2745, -3.3577, -3.3136, -3.2968, -3.3361]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs[0, :, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.2745, -3.3577, -3.3136,  ..., -3.3595, -3.3186, -3.3953],\n",
       "         [-3.2745, -3.3577, -3.3136,  ..., -3.3595, -3.3186, -3.3953],\n",
       "         [-3.2745, -3.3577, -3.3136,  ..., -3.3596, -3.3186, -3.3953],\n",
       "         [-3.2745, -3.3577, -3.3136,  ..., -3.3595, -3.3186, -3.3953]],\n",
       "\n",
       "        [[-3.2743, -3.3684, -3.3266,  ..., -3.3557, -3.3265, -3.3885],\n",
       "         [-3.2743, -3.3683, -3.3266,  ..., -3.3557, -3.3265, -3.3885],\n",
       "         [-3.2743, -3.3684, -3.3266,  ..., -3.3557, -3.3265, -3.3885],\n",
       "         [-3.2743, -3.3684, -3.3266,  ..., -3.3557, -3.3265, -3.3885]],\n",
       "\n",
       "        [[-3.2737, -3.3746, -3.3328,  ..., -3.3527, -3.3312, -3.3853],\n",
       "         [-3.2737, -3.3746, -3.3327,  ..., -3.3527, -3.3312, -3.3853],\n",
       "         [-3.2737, -3.3746, -3.3328,  ..., -3.3527, -3.3312, -3.3853],\n",
       "         [-3.2737, -3.3746, -3.3328,  ..., -3.3527, -3.3312, -3.3852]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824],\n",
       "         [-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824],\n",
       "         [-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824],\n",
       "         [-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824]],\n",
       "\n",
       "        [[-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824],\n",
       "         [-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824],\n",
       "         [-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824],\n",
       "         [-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824]],\n",
       "\n",
       "        [[-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824],\n",
       "         [-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824],\n",
       "         [-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824],\n",
       "         [-3.2734, -3.3837, -3.3410,  ..., -3.3464, -3.3374, -3.3824]]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.log_softmax(log_probs, dim=-1)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6., 15., 21., 18., 27., 13., 15., 14., 20.,  8., 19., 27.,  8.,  1.,\n",
       "          4., 27., 13.,  1.,  4.,  5., 27.,  7., 18.,  5.,  1., 20., 27.,  3.,\n",
       "          8.,  1., 14.,  7.,  5., 19., 27.,  8.,  5., 27.,  2., 15., 18.,  5.,\n",
       "         27.,  8.,  9., 13., 19.,  5., 12.,  6., 27., 13., 15., 18.,  5., 27.,\n",
       "         12.,  9., 11.,  5., 27.,  1., 27., 13.,  1., 14., 27.,  8.,  9., 19.,\n",
       "         27., 13.,  1., 14., 14.,  5., 18., 27., 23.,  1., 19., 27., 13., 21.,\n",
       "          3.,  8., 27., 13., 15., 18.,  5., 27.,  3., 15., 14., 19.,  9.,  4.,\n",
       "          5., 18.,  5.,  4., 27.,  1., 14.,  4., 27.,  7., 18.,  1., 22.,  5.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.],\n",
       "        [23.,  9., 20.,  8., 27., 19., 15., 21., 16., 27.,  1., 14.,  4., 27.,\n",
       "          6.,  9., 19.,  8., 27., 19.,  5., 18., 22.,  5., 27., 23.,  8.,  9.,\n",
       "         20.,  5., 27., 23.,  9., 14.,  5., 19., 27., 19., 21.,  3.,  8., 27.,\n",
       "          1., 19., 27., 18.,  8.,  5.,  9., 14., 27., 23.,  9., 14.,  5., 27.,\n",
       "         19.,  1., 21., 20.,  5., 18., 14.,  5., 27., 15., 18., 27., 23.,  8.,\n",
       "          9., 20.,  5., 27.,  2., 21., 18.,  7., 21., 14.,  4., 25.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.],\n",
       "        [20.,  8.,  5., 25., 27.,  8.,  1., 22.,  5., 27., 11., 14., 15., 23.,\n",
       "         14., 27., 13.,  5., 27., 13., 21.,  3.,  8., 27., 12., 15., 14.,  7.,\n",
       "          5., 18., 27.,  2., 21., 20., 27., 14.,  5., 22.,  5., 18., 27.,  8.,\n",
       "         15., 14., 15., 18., 27., 13.,  5., 27., 23.,  9., 20.,  8., 27.,  1.,\n",
       "         14., 25., 27.,  6.,  1., 13.,  9., 12.,  9.,  1., 18.,  9., 20., 25.,\n",
       "         27., 20.,  8., 15., 21.,  7.,  8., 27.,  8.,  1., 18.,  4., 12., 25.,\n",
       "         27.,  1., 27.,  4.,  1., 25., 27., 16.,  1., 19., 19.,  5., 19., 27.,\n",
       "         23.,  9., 20.,  8., 15., 21., 20., 27., 13., 25., 27.,  2., 18.,  9.,\n",
       "         14.,  7.,  9., 14.,  7., 27., 20.,  8.,  5., 13., 27.,  6., 15., 15.,\n",
       "          4.],\n",
       "        [ 1., 14.,  4., 27., 23.,  8.,  1., 20., 27.,  1., 12., 12., 21., 18.,\n",
       "          5., 13.,  5., 14., 20., 19., 27., 15., 18., 27., 23.,  8.,  1., 20.,\n",
       "         27., 22.,  1., 14., 20.,  1.,  7.,  5., 19., 27., 21., 16., 15., 14.,\n",
       "         27., 20.,  8.,  5., 27.,  6., 15., 18.,  5.,  8.,  5.,  1.,  4., 27.,\n",
       "         15.,  6., 27., 20.,  8.,  5., 27., 15., 20.,  8.,  5., 18., 19., 27.,\n",
       "         19.,  8., 15., 23.,  5.,  4., 27., 20.,  8.,  1., 20., 27., 20.,  8.,\n",
       "         15., 21., 27., 19.,  8., 15., 21., 12.,  4., 19., 20., 27., 20., 21.,\n",
       "         18., 14., 27., 20.,  8., 25., 27.,  6., 15., 15., 20., 19., 20.,  5.,\n",
       "         16., 19., 27., 21., 14., 20., 15., 27., 20.,  8.,  5., 13.,  0.,  0.,\n",
       "          0.]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0),\n",
       " tensor(-194.7010, grad_fn=<MinBackward1>),\n",
       " tensor(0., grad_fn=<MaxBackward1>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(log_probs).sum(), torch.min(log_probs), torch.max(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0.), tensor(27.))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(targets).sum(), torch.min(targets), torch.max(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(128), tensor(128))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(input_lengths).sum(), torch.min(input_lengths), torch.max(input_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(36), tensor(178))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(target_lengths).sum(), torch.min(target_lengths), torch.max(target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.3639, -3.3025, -3.3200,  ..., -3.2768, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3197,  ..., -3.2787, -3.3583, -3.3350],\n",
       "         [-3.3616, -3.3039, -3.3194,  ..., -3.2774, -3.3583, -3.3341],\n",
       "         ...,\n",
       "         [-3.3628, -3.3032, -3.3197,  ..., -3.2777, -3.3584, -3.3348],\n",
       "         [-3.3579, -3.3041, -3.3199,  ..., -3.2759, -3.3585, -3.3329],\n",
       "         [-3.3601, -3.3042, -3.3195,  ..., -3.2770, -3.3584, -3.3336]],\n",
       "\n",
       "        [[-3.3606, -3.3038, -3.3199,  ..., -3.2769, -3.3586, -3.3336],\n",
       "         [-3.3636, -3.3029, -3.3197,  ..., -3.2787, -3.3583, -3.3350],\n",
       "         [-3.3549, -3.3037, -3.3224,  ..., -3.2755, -3.3582, -3.3314],\n",
       "         ...,\n",
       "         [-3.3635, -3.3027, -3.3198,  ..., -3.2785, -3.3582, -3.3352],\n",
       "         [-3.3472, -3.3010, -3.3271,  ..., -3.2754, -3.3644, -3.3276],\n",
       "         [-3.3640, -3.3030, -3.3198,  ..., -3.2760, -3.3582, -3.3350]],\n",
       "\n",
       "        [[-3.3629, -3.3033, -3.3199,  ..., -3.2773, -3.3585, -3.3344],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3582, -3.3349],\n",
       "         [-3.3621, -3.3036, -3.3195,  ..., -3.2778, -3.3583, -3.3343],\n",
       "         ...,\n",
       "         [-3.3636, -3.3023, -3.3204,  ..., -3.2785, -3.3581, -3.3347],\n",
       "         [-3.3562, -3.3041, -3.3207,  ..., -3.2760, -3.3585, -3.3323],\n",
       "         [-3.3630, -3.3035, -3.3198,  ..., -3.2754, -3.3582, -3.3346]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         ...,\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349]],\n",
       "\n",
       "        [[-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         ...,\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349]],\n",
       "\n",
       "        [[-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         ...,\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349],\n",
       "         [-3.3635, -3.3029, -3.3196,  ..., -3.2787, -3.3583, -3.3349]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
